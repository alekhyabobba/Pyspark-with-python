{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTzzNQO6KmMC1Fmza8Ppzy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alekhyabobba/Pyspark-with-python/blob/main/Data_Cleaning_using_pyspark_and_filter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning\n",
        "## Handling Missing values\n",
        "\n",
        "\n",
        "*   Dropping columns \n",
        "\n",
        "*   Dropping rows\n",
        "*   Various parameters in dropping functionalities\n",
        "\n",
        "\n",
        "*   Imputing Null values with measure of central tendency\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dfo4g-6wjBpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kxbQmTLi4SO",
        "outputId": "fee9c1fb-b703-44dd-90ce-e8c856cccdfc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 45 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 38.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=98a57b0858d10f8d570c95f20eb7ecdffcf0f98d1179def754edda9da1f539a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Practice').getOrCreate()"
      ],
      "metadata": {
        "id": "GfyJmjPljeTt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUM8ZeoxoXtI",
        "outputId": "5e558512-4967-4e23-f16a-405a7187eb57"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df = spark.read.csv('/content/drive/My Drive/test2.csv',header = True,inferSchema = True)"
      ],
      "metadata": {
        "id": "pfhM9pLvjk3i"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.printSchema()"
      ],
      "metadata": {
        "id": "rqohUnRnlcSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "415da4c1-570c-49c5-e559-da7663ff9941"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khD_W60To6G3",
        "outputId": "32a6f2ee-b946-4e98-825c-7ce0422249b2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  36|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We havn't imputed into datframe just recalling working of drop\n",
        "pyspark_df.drop('Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MIyBPyHqTg_",
        "outputId": "709f3d92-34ff-4c34-8ab8-f965e6718212"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+------+\n",
            "| age|Experience|Salary|\n",
            "+----+----------+------+\n",
            "|  31|        10| 30000|\n",
            "|  30|         8| 25000|\n",
            "|  29|         4| 20000|\n",
            "|  24|         3| 20000|\n",
            "|  21|         1| 15000|\n",
            "|  23|         2| 18000|\n",
            "|null|      null| 40000|\n",
            "|  34|        10| 38000|\n",
            "|  36|      null|  null|\n",
            "+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping rows with null values\n",
        "pyspark_df.na.drop().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ssc643xoqax9",
        "outputId": "76ea815f-325d-4a80-e8f8-7e53e9de906c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#There are mainly three attributes how,thresh,subset\n",
        "# We are using how = 'any' this is default attribute any all the rows with null values will be deleted\n",
        "pyspark_df.na.drop(how = 'any').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRb9g8H1qoAV",
        "outputId": "8e0fdd1a-c94d-4421-86f4-ce405c492d7f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how = \"all\" will drop rows only if all the values are null\n",
        "# We could observe no values are deleted here as there is no row with complete null values\n",
        "pyspark_df.na.drop(how = 'all').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOJlLXUvqzSU",
        "outputId": "12daccec-cbae-4beb-d934-70892c125bca"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  36|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Thresh attribute sets the limit for number of non null values to be present in the row to get dropped\n",
        "pyspark_df.na.drop(how ='any',thresh =1).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRNGQThrsCFl",
        "outputId": "d073a8b3-ad03-4f1c-fa51-252d42dcd1a9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  36|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since the last row has only one non null value the record is dropped\n",
        "pyspark_df.na.drop(how ='any',thresh =2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgOTrd-YsZ7E",
        "outputId": "17767678-c4d1-4417-c861-6739e0080c5a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Since last 2 records have only 2 non null values records are dropped\n",
        "#Thresh implies number of non null values to be present in a row\n",
        "pyspark_df.na.drop(how ='any',thresh =3).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqqtjOpmsvYW",
        "outputId": "b92fe483-2dec-4782-90cc-0351fb538a40"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|     null| 34|        10| 38000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#subset : If we want a column to be non null we need to drop records having null values in that particular column\n",
        "  #we use subset in this case. We can give multiple column names in subset attribute.\n",
        "#Here we can see age column doesn't have null values. row is dropped where age has null value\n",
        "pyspark_df.na.drop(how ='any',subset=['Age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNLkUsa9s6sV",
        "outputId": "d2c2a747-c9b2-4f42-edb9-db9437b4565a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|     null| 34|        10| 38000|\n",
            "|     null| 36|      null|  null|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.na.drop(how ='any',subset=['Age','experience']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig1FbpsXtoJp",
        "outputId": "91298a65-47da-42f9-acb2-e08817fc3b16"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|     null| 34|        10| 38000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imputing Missing values"
      ],
      "metadata": {
        "id": "hpXVja_xuEJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Filling the missing values/Null values with any name\n",
        "pyspark_df.na.fill('Value is missed here',['Name']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7TTM8Ayt46N",
        "outputId": "2a0ebc7e-cb3c-491e-b5f7-3dab19bebdb2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----+----------+------+\n",
            "|                Name| age|Experience|Salary|\n",
            "+--------------------+----+----------+------+\n",
            "|               Krish|  31|        10| 30000|\n",
            "|           Sudhanshu|  30|         8| 25000|\n",
            "|               Sunny|  29|         4| 20000|\n",
            "|                Paul|  24|         3| 20000|\n",
            "|              Harsha|  21|         1| 15000|\n",
            "|             Shubham|  23|         2| 18000|\n",
            "|              Mahesh|null|      null| 40000|\n",
            "|Value is missed here|  34|        10| 38000|\n",
            "|Value is missed here|  36|      null|  null|\n",
            "+--------------------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Since age,Experience columns are integer type replaced null value with 0\n",
        "pyspark_df.na.fill(0,['age','Experience']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JziWOiOluDaQ",
        "outputId": "cc31b2f4-80cc-4103-e034-9bc8a63599e5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|   Mahesh|  0|         0| 40000|\n",
            "|     null| 34|        10| 38000|\n",
            "|     null| 36|         0|  null|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imputing missing values with median\n",
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols=['age', 'Experience', 'Salary'], \n",
        "    outputCols=[\"{}_imputed\".format(c) for c in ['age', 'Experience', 'Salary']]\n",
        "    ).setStrategy(\"median\")"
      ],
      "metadata": {
        "id": "0J6adL5cu9CV"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add imputation cols to df\n",
        "imputer.fit(pyspark_df).transform(pyspark_df).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t25Fic7Gv4Y_",
        "outputId": "3ec81c4f-4599-459a-86e5-ea192576ff96"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|     Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|    Krish|  31|        10| 30000|         31|                10|         30000|\n",
            "|Sudhanshu|  30|         8| 25000|         30|                 8|         25000|\n",
            "|    Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
            "|     Paul|  24|         3| 20000|         24|                 3|         20000|\n",
            "|   Harsha|  21|         1| 15000|         21|                 1|         15000|\n",
            "|  Shubham|  23|         2| 18000|         23|                 2|         18000|\n",
            "|   Mahesh|null|      null| 40000|         29|                 4|         40000|\n",
            "|     null|  34|        10| 38000|         34|                10|         38000|\n",
            "|     null|  36|      null|  null|         36|                 4|         20000|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Filter operation\n",
        "\n",
        "\n",
        "*   Filter operation\n",
        "\n",
        "*   &,|,==\n",
        "*   ~\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gDUkojF_xEUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtering the employees with slaries less than 20k\n",
        "pyspark_df.filter(\"Salary<=20000\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf1xjn7VxD9G",
        "outputId": "155e287c-4648-4afc-d0da-3567e4302be7"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Filtering name and age of  employees with slaries less than 20k\n",
        "pyspark_df.filter(\"Salary<=20000\").select(['Name','Age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6egeybeEwbm1",
        "outputId": "a5f9cfee-f5e3-4b4e-df17-f09afd41d9a3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+\n",
            "|   Name|Age|\n",
            "+-------+---+\n",
            "|  Sunny| 29|\n",
            "|   Paul| 24|\n",
            "| Harsha| 21|\n",
            "|Shubham| 23|\n",
            "+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtering the employees with slaaries ranging between 15k to 20k\n",
        "pyspark_df.filter((pyspark_df['Salary'] <=20000)&(pyspark_df['Salary']>15000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFeENJ3hyIh1",
        "outputId": "31dfb0ec-bc30-48c3-e303-c7770a47eabc"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyspark_df.filter((pyspark_df['Salary'] <=20000)|(pyspark_df['Salary']>25000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uopfnBhypTW",
        "outputId": "78d9c2fe-e6a7-4e7b-f477-8e8d2255b40b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----------+------+\n",
            "|   Name| age|Experience|Salary|\n",
            "+-------+----+----------+------+\n",
            "|  Krish|  31|        10| 30000|\n",
            "|  Sunny|  29|         4| 20000|\n",
            "|   Paul|  24|         3| 20000|\n",
            "| Harsha|  21|         1| 15000|\n",
            "|Shubham|  23|         2| 18000|\n",
            "| Mahesh|null|      null| 40000|\n",
            "|   null|  34|        10| 38000|\n",
            "+-------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To find out the employees whose salaries are not more than 20k\n",
        "pyspark_df.filter(~(pyspark_df['Salary']>20000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyJ0IXuZy07W",
        "outputId": "b9ff88b7-fa12-4645-a95f-fdceb2c65f98"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sm6dkktMzPul"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}